{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1uyMXiflbKoA","executionInfo":{"status":"ok","timestamp":1714018417217,"user_tz":-330,"elapsed":53681,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"}},"outputId":"4edf044c-5ac7-4ec7-e50c-b7219ede61ff"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["AdaBoost Classifier Accuracy: 0.6587550380653829\n"]}],"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Folder ID of the Google Drive folder containing the CSV files\n","folder_id = '13F9CFT1LSEWeMtNUScOYNRqndhpkYCiu'  # Replace 'FOLDER_ID' with the actual folder ID\n","\n","# List all files in the specified folder\n","file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()\n","\n","# Filter out only the CSV files\n","csv_files = [file for file in file_list if file['title'].endswith('.csv')]\n","\n","# Download CSV files from Google Drive\n","dfs = []\n","for file in csv_files:\n","    file_id = file['id']\n","    downloaded = drive.CreateFile({'id': file_id})\n","    downloaded.GetContentFile(f\"{downloaded['title']}\")\n","    dfs.append(pd.read_csv(f\"{downloaded['title']}\"))\n","\n","# Concatenate data from CSV files\n","combined_df = pd.concat(dfs, ignore_index=True)\n","\n","# Data preprocessing\n","combined_df.dropna(subset=['Statement'], inplace=True)\n","\n","# Split the data into train and test sets\n","X = combined_df['Statement']\n","y = combined_df['Type of Fallacy']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Feature extraction using TF-IDF\n","vectorizer = TfidfVectorizer()\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf = vectorizer.transform(X_test)\n","\n","# AdaBoost Classifier with reduced parameters\n","adaboost_classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), n_estimators=100, learning_rate=0.3)\n","adaboost_classifier.fit(X_train_tfidf, y_train)\n","\n","# Evaluate the AdaBoost Classifier\n","adaboost_accuracy = accuracy_score(y_test, adaboost_classifier.predict(X_test_tfidf))\n","\n","# Print the accuracy\n","print(\"AdaBoost Classifier Accuracy:\", adaboost_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVLV2_PN_3Un","executionInfo":{"status":"ok","timestamp":1714018995085,"user_tz":-330,"elapsed":508,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"}},"outputId":"c6efbe06-1cf4-4cb0-9112-13b483f09b4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Fallacy Probabilities:\n","Anecdotal: 0.00014761598844381148\n","Appeal to Authority Fallacy: 5.6839695712700756e-05\n","Appeal to Nature Fallacy: 0.10029262941974744\n","Appeal to Worse Problems Fallacy: 0.0008673094117773975\n","Bandwagon Fallacy: 0.0027795042558456406\n","Circular Reasoning: 0.024002073726587848\n","False Cause: 0.007716197438610764\n","Genetic Fallacy: 0.2158381174223862\n","Irrelevant Authority: 0.049167108663016795\n","Loaded Question: 7.895870138441785e-06\n","Middle Ground Fallacy: 0.0006198682527265694\n","Non Sequitur: 0.1429043664773341\n","Personal Incredulity: 0.14481749939462085\n","Special Pleading: 0.2177566263313954\n","The Gambler's Fallacy: 0.09302634765165607\n"]}],"source":["# Function to predict fallacy type with probabilities\n","def predict_fallacy_probabilities(statement):\n","    statement_tfidf = vectorizer.transform([statement])\n","    probabilities = adaboost_classifier.predict_proba(statement_tfidf)[0]\n","    fallacy_types = adaboost_classifier.classes_\n","    result = {fallacy_types[i]: probabilities[i] for i in range(len(fallacy_types))}\n","    return result\n","\n","# Example usage:\n","statement = \"Your argument is invalid because you are too young to understand.\"\n","predicted_probabilities = predict_fallacy_probabilities(statement)\n","print(\"Predicted Fallacy Probabilities:\")\n","for fallacy_type, probability in predicted_probabilities.items():\n","    print(f\"{fallacy_type}: {probability}\")"]},{"cell_type":"code","source":["new_statement = \"Attacking an opposing individual instead of their argument. For example, dismissing climate activist Greta Thunberg due to her young age instead of her ideas.\"\n","\n","# Preprocess the new statement\n","new_statement_tfidf = vectorizer.transform([new_statement])\n","\n","# Predict the fallacy type\n","predicted_fallacy = adaboost_classifier.predict(new_statement_tfidf)\n","\n","# Print the predicted fallacy type\n","print(\"Predicted Fallacy Type:\", predicted_fallacy[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"EVB30z4Nh-zM","executionInfo":{"status":"error","timestamp":1714020594680,"user_tz":-330,"elapsed":12,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"}},"outputId":"187b1b34-2ace-49c1-8e0d-e767c647ac8e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"X has 4854 features, but AdaBoostClassifier is expecting 5467 features as input.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-0b7fdaf634f8>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Predict the fallacy type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpredicted_fallacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaboost_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_statement_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Print the predicted fallacy type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \"\"\"\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \"\"\"\n\u001b[1;32m    760\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Only called to validate X in non-fit methods, therefore reset=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         return self._validate_data(\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: X has 4854 features, but AdaBoostClassifier is expecting 5467 features as input."]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3uDv61k9yoA","executionInfo":{"status":"ok","timestamp":1714020101004,"user_tz":-330,"elapsed":24709,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"}},"outputId":"d3bce61b-ca34-4a0d-e207-e3ae73c6fd2c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Predicted Fallacy Probabilities:\n","Anecdotal: 8.732886113761646e-05\n","Appeal to Authority Fallacy: 4.477275353950533e-05\n","Appeal to Nature Fallacy: 0.11287061738996047\n","Appeal to Worse Problems Fallacy: 0.0005016663735114283\n","Bandwagon Fallacy: 0.0017287259533690178\n","Circular Reasoning: 0.03060675344121273\n","False Cause: 0.008728520742472727\n","Genetic Fallacy: 0.1480376918452858\n","Irrelevant Authority: 0.035348529931279044\n","Loaded Question: 1.2885542666625987e-05\n","Middle Ground Fallacy: 0.0003564150659120162\n","Non Sequitur: 0.0665182115856579\n","Personal Incredulity: 0.10289331469760893\n","Special Pleading: 0.4185527994595116\n","The Gambler's Fallacy: 0.07371176635687457\n"]}],"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Folder ID of the Google Drive folder containing the CSV files\n","folder_id = '13F9CFT1LSEWeMtNUScOYNRqndhpkYCiu'  # Replace 'FOLDER_ID' with the actual folder ID\n","\n","# List all files in the specified folder\n","file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()\n","\n","# Filter out only the CSV files\n","csv_files = [file for file in file_list if file['title'].endswith('.csv')]\n","\n","# Download CSV files from Google Drive\n","dfs = []\n","for file in csv_files:\n","    file_id = file['id']\n","    downloaded = drive.CreateFile({'id': file_id})\n","    downloaded.GetContentFile(f\"{downloaded['title']}\")\n","    dfs.append(pd.read_csv(f\"{downloaded['title']}\"))\n","\n","# Concatenate data from CSV files\n","combined_df = pd.concat(dfs, ignore_index=True)\n","\n","# Data preprocessing\n","combined_df.dropna(subset=['Statement'], inplace=True)\n","\n","# Feature extraction using TF-IDF\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(combined_df['Statement'])\n","y = combined_df['Type of Fallacy']\n","\n","# Train the classifier\n","adaboost_classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), n_estimators=100, learning_rate=0.3)\n","adaboost_classifier.fit(X, y)\n","\n","# Function to predict fallacy type with probabilities\n","def predict_fallacy_probabilities(statement):\n","    statement_tfidf = vectorizer.transform([statement])\n","    probabilities = adaboost_classifier.predict_proba(statement_tfidf)[0]\n","    fallacy_types = adaboost_classifier.classes_\n","    result = {fallacy_types[i]: probabilities[i] for i in range(len(fallacy_types))}\n","    return result\n","\n","# Example usage:\n","statement = \"Your argument is invalid because you are too young to understand.\"\n","predicted_probabilities = predict_fallacy_probabilities(statement)\n","print(\"Predicted Fallacy Probabilities:\")\n","for fallacy_type, probability in predicted_probabilities.items():\n","    print(f\"{fallacy_type}: {probability}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-um5N1WDzBJp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714020076297,"user_tz":-330,"elapsed":7,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"}},"outputId":"5e93097a-674e-4fa4-f29f-2c12fc86d032"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Probabilities:\n","[[2.66038404e-04 9.25643894e-05 2.45131831e-02 2.35089155e-03\n","  6.83522852e-03 1.76143560e-02 3.50603559e-02 1.82139874e-01\n","  4.62438553e-02 1.21202226e-05 1.64130615e-03 2.56660558e-02\n","  1.91438583e-01 1.71921515e-01 2.94204073e-01]\n"," [8.31489597e-02 1.19967887e-04 2.28457794e-02 1.85182702e-03\n","  2.02704421e-03 2.87596265e-01 4.03697736e-02 1.11252856e-02\n","  1.11438261e-01 1.26996733e-05 2.28136508e-04 1.77810370e-01\n","  1.60356689e-01 9.54158269e-02 5.65311456e-03]\n"," [1.10916520e-04 5.99276973e-05 2.17475700e-03 4.20483582e-01\n","  8.41617444e-03 1.15103367e-03 1.04631154e-01 5.68584170e-02\n","  2.34176505e-01 6.96188314e-06 2.14548782e-03 8.80978801e-03\n","  7.13025698e-02 8.00307316e-02 9.64199344e-03]\n"," [2.22899981e-04 2.06234319e-05 7.38429761e-04 6.04827622e-01\n","  8.11286108e-04 2.28956928e-04 5.47897022e-02 2.73544545e-02\n","  2.52117472e-02 4.48528741e-06 7.50253170e-04 4.26293142e-03\n","  1.17285342e-01 1.51209067e-01 1.22821990e-02]\n"," [1.51820053e-01 4.05815265e-04 1.23993668e-02 5.75796387e-03\n","  7.12135866e-03 3.62477060e-03 1.81475147e-01 5.46951947e-03\n","  1.78867481e-01 4.10289719e-05 4.78969549e-04 1.28092081e-01\n","  1.61355415e-01 1.60124263e-01 2.96676774e-03]]\n","Predicted Classes:\n","[\"The Gambler's Fallacy\" 'Circular Reasoning'\n"," 'Appeal to Worse Problems Fallacy' 'Appeal to Worse Problems Fallacy'\n"," 'False Cause']\n","Similarity Percentage:\n","[29.42040731 28.75962648 42.04835821 60.48276217 18.14751474]\n"]}],"source":["# Get the predicted probabilities for each class label\n","y_pred_proba = adaboost_classifier.predict_proba(X_test_tfidf)\n","\n","# Print the predicted probabilities for the first few samples\n","print(\"Predicted Probabilities:\")\n","print(y_pred_proba[:5])\n","\n","# Calculate the maximum probability along each row to get the predicted class\n","predicted_classes = adaboost_classifier.classes_[y_pred_proba.argmax(axis=1)]\n","\n","# Print the predicted classes for the first few samples\n","print(\"Predicted Classes:\")\n","print(predicted_classes[:5])\n","\n","# Calculate the similarity percentage\n","similarity_percentage = y_pred_proba.max(axis=1) * 100\n","\n","# Print the similarity percentage for the first few samples\n","print(\"Similarity Percentage:\")\n","print(similarity_percentage[:5])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":997371,"status":"ok","timestamp":1714020074792,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"},"user_tz":-330},"id":"ldwYhHUjhNGN","outputId":"d7d936bf-c716-4d02-8deb-80def8de8dd9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Best Model Accuracy: 0.8889386475593373\n"]}],"source":["# Import necessary libraries\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_selection import SelectKBest, chi2\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Folder ID of the Google Drive folder containing the CSV files\n","folder_id = '13F9CFT1LSEWeMtNUScOYNRqndhpkYCiu'  # Replace 'FOLDER_ID' with the actual folder ID\n","\n","# List all files in the specified folder\n","file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()\n","\n","# Filter out only the CSV files\n","csv_files = [file for file in file_list if file['title'].endswith('.csv')]\n","\n","# Download CSV files from Google Drive\n","dfs = []\n","for file in csv_files:\n","    file_id = file['id']\n","    downloaded = drive.CreateFile({'id': file_id})\n","    downloaded.GetContentFile(f\"{downloaded['title']}\")\n","    dfs.append(pd.read_csv(f\"{downloaded['title']}\"))\n","\n","# Concatenate data from CSV files\n","combined_df = pd.concat(dfs, ignore_index=True)\n","\n","# Data preprocessing\n","combined_df.dropna(subset=['Statement'], inplace=True)\n","\n","# Split the data into train and test sets\n","X = combined_df['Statement']\n","y = combined_df['Type of Fallacy']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Feature extraction using TF-IDF\n","vectorizer = TfidfVectorizer()\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf = vectorizer.transform(X_test)\n","\n","# Create a pipeline with feature selection and AdaBoost classifier\n","pipeline = Pipeline([\n","    ('feature_selection', SelectKBest(chi2)),\n","    ('classifier', AdaBoostClassifier(base_estimator=DecisionTreeClassifier()))\n","])\n","\n","# Define a grid of hyperparameters for grid search\n","param_grid = {\n","    'feature_selection__k': [100, 300, 500],  # Adjust these values based on your dataset\n","    'classifier__base_estimator__max_depth': [1, 2],  # Decision tree depths to prevent overfitting\n","    'classifier__n_estimators': [50, 100, 200],  # Number of estimators\n","    'classifier__learning_rate': [0.01, 0.1, 0.3]  # Learning rates\n","}\n","\n","# Initialize GridSearchCV with the pipeline and parameter grid\n","grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","\n","# Fit the grid search to the training data\n","grid_search.fit(X_train_tfidf, y_train)\n","\n","# Get the best model from grid search\n","best_model = grid_search.best_estimator_\n","\n","# Evaluate the best model on the test set\n","best_model_accuracy = accuracy_score(y_test, best_model.predict(X_test_tfidf))\n","\n","# Print the accuracy of the best model\n","print(\"Best Model Accuracy:\", best_model_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOEcRvo2OXxz","executionInfo":{"status":"ok","timestamp":1714020594679,"user_tz":-330,"elapsed":493678,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"}},"outputId":"2fb45bf2-3770-4a1c-8d90-19772bb12449"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Best Model Accuracy: 0.9090909090909091\n","Classification Report:\n","                                   precision    recall  f1-score   support\n","\n","                       Anecdotal       1.00      0.87      0.93       118\n","     Appeal to Authority Fallacy       1.00      1.00      1.00        97\n","        Appeal to Nature Fallacy       1.00      0.99      0.99        99\n","Appeal to Worse Problems Fallacy       1.00      1.00      1.00       647\n","               Bandwagon Fallacy       0.97      0.95      0.96       128\n","              Circular Reasoning       0.61      1.00      0.76       266\n","                     False Cause       0.98      0.88      0.92       112\n","                 Genetic Fallacy       0.99      0.73      0.84        96\n","            Irrelevant Authority       0.95      0.77      0.85       113\n","                 Loaded Question       0.99      0.97      0.98       127\n","           Middle Ground Fallacy       1.00      0.96      0.98        23\n","                    Non Sequitur       0.88      0.94      0.91       101\n","            Personal Incredulity       0.93      0.77      0.85       106\n","                Special Pleading       0.97      0.30      0.46       106\n","           The Gambler's Fallacy       1.00      0.95      0.97        94\n","\n","                        accuracy                           0.91      2233\n","                       macro avg       0.95      0.87      0.89      2233\n","                    weighted avg       0.94      0.91      0.91      2233\n","\n"]}],"source":["# Import necessary libraries\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_selection import SelectKBest, chi2\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Folder ID of the Google Drive folder containing the CSV files\n","folder_id = '13F9CFT1LSEWeMtNUScOYNRqndhpkYCiu'  # Replace 'FOLDER_ID' with the actual folder ID\n","\n","# List all files in the specified folder\n","file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()\n","\n","# Filter out only the CSV files\n","csv_files = [file for file in file_list if file['title'].endswith('.csv')]\n","\n","# Download CSV files from Google Drive\n","dfs = []\n","for file in csv_files:\n","    file_id = file['id']\n","    downloaded = drive.CreateFile({'id': file_id})\n","    downloaded.GetContentFile(f\"{downloaded['title']}\")\n","    dfs.append(pd.read_csv(f\"{downloaded['title']}\"))\n","\n","# Concatenate data from CSV files\n","combined_df = pd.concat(dfs, ignore_index=True)\n","\n","# Data preprocessing\n","combined_df.dropna(subset=['Statement'], inplace=True)\n","\n","# Text preprocessing function\n","def preprocess_text(text):\n","    lemmatizer = WordNetLemmatizer()\n","    words = text.split()\n","    cleaned_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stopwords.words('english')]\n","    return \" \".join(cleaned_words)\n","\n","# Apply text preprocessing\n","combined_df['Statement'] = combined_df['Statement'].apply(preprocess_text)\n","\n","# Split the data into train and test sets\n","X = combined_df['Statement']\n","y = combined_df['Type of Fallacy']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Feature extraction using TF-IDF\n","vectorizer = TfidfVectorizer()\n","X_train_tfidf = vectorizer.fit_transform(X_train)\n","X_test_tfidf = vectorizer.transform(X_test)\n","\n","# Create a pipeline with feature selection and RandomForest classifier\n","pipeline = Pipeline([\n","    ('feature_selection', SelectKBest(chi2)),\n","    ('classifier', RandomForestClassifier())\n","])\n","\n","# Define a grid of hyperparameters for grid search\n","param_grid = {\n","    'feature_selection__k': [100, 300, 500],\n","    'classifier__max_depth': [10, 20, 30],\n","    'classifier__n_estimators': [100, 200, 300],\n","    'classifier__min_samples_split': [2, 5, 10]\n","}\n","\n","# Initialize GridSearchCV with the pipeline and parameter grid\n","grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","\n","# Fit the grid search to the training data\n","grid_search.fit(X_train_tfidf, y_train)\n","\n","# Get the best model from grid search\n","best_model = grid_search.best_estimator_\n","\n","# Evaluate the best model on the test set\n","predictions = best_model.predict(X_test_tfidf)\n","best_model_accuracy = accuracy_score(y_test, predictions)\n","\n","# Print the accuracy and classification report of the best model\n","print(\"Best Model Accuracy:\", best_model_accuracy)\n","print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"]},{"cell_type":"code","source":["# Function to predict the probability of each type of fallacy in a sentence\n","def predict_fallacy_probabilities(sentence, vectorizer, model):\n","    # Preprocess the sentence using the same preprocessing function\n","    preprocessed_sentence = preprocess_text(sentence)\n","\n","    # Transform the sentence using the trained TF-IDF vectorizer\n","    sentence_tfidf = vectorizer.transform([preprocessed_sentence])\n","\n","    # Use the trained model to predict the probabilities for each fallacy\n","    fallacy_probabilities = model.predict_proba(sentence_tfidf)\n","\n","    return fallacy_probabilities[0]\n","\n","# Example usage:\n","input_sentence = \"If we make an exception for Bijal’s service dog, then other people will want to bring their dogs. Then everybody will bring their dog, and before you know it, our restaurant will be overrun with dogs, their slobber, their hair, and all the noise they make, and nobody will want to eat here anymore.\"\n","fallacy_probabilities = predict_fallacy_probabilities(input_sentence, vectorizer, best_model)\n","\n","# Assuming the model classes are accessible via best_model.classes_\n","fallacy_types = best_model.classes_\n","\n","# Print the probabilities for each fallacy type\n","print(\"Probabilities for each type of fallacy:\")\n","for fallacy, probability in zip(fallacy_types, fallacy_probabilities):\n","    print(f\"{fallacy}: {probability:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVKKFBsCmne-","executionInfo":{"status":"ok","timestamp":1714022257302,"user_tz":-330,"elapsed":1555,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"}},"outputId":"a3300e12-6f83-43b4-877a-6f9c977953a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilities for each type of fallacy:\n","Anecdotal: 0.0292\n","Appeal to Authority Fallacy: 0.0310\n","Appeal to Nature Fallacy: 0.0125\n","Appeal to Worse Problems Fallacy: 0.0270\n","Bandwagon Fallacy: 0.0512\n","Circular Reasoning: 0.1995\n","False Cause: 0.0566\n","Genetic Fallacy: 0.0819\n","Irrelevant Authority: 0.0983\n","Loaded Question: 0.0497\n","Middle Ground Fallacy: 0.0052\n","Non Sequitur: 0.0631\n","Personal Incredulity: 0.1739\n","Special Pleading: 0.0946\n","The Gambler's Fallacy: 0.0263\n"]}]},{"cell_type":"code","source":["# Function to predict the type of fallacy in a sentence\n","def predict_fallacy(sentence, vectorizer, model):\n","    # Preprocess the sentence using the same preprocessing function\n","    preprocessed_sentence = preprocess_text(sentence)\n","\n","    # Transform the sentence using the trained TF-IDF vectorizer\n","    sentence_tfidf = vectorizer.transform([preprocessed_sentence])\n","\n","    # Use the trained model to predict the fallacy\n","    fallacy_prediction = model.predict(sentence_tfidf)\n","\n","    return fallacy_prediction[0]\n","\n","# Example usage:\n","input_sentence = \"If we make an exception for Bijal’s service dog, then other people will want to bring their dogs. Then everybody will bring their dog, and before you know it, our restaurant will be overrun with dogs, their slobber, their hair, and all the noise they make, and nobody will want to eat here anymore.\"\n","fallacy_type = predict_fallacy(input_sentence, vectorizer, best_model)\n","print(f\"The predicted fallacy for the input sentence is: {fallacy_type}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B4l8yfTulmVD","executionInfo":{"status":"ok","timestamp":1714022269179,"user_tz":-330,"elapsed":1368,"user":{"displayName":"Abhijeet Baloji","userId":"15651678516397668595"}},"outputId":"84ad1861-9d06-41b7-e441-3b2c0acfbcd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The predicted fallacy for the input sentence is: Circular Reasoning\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1W_dAaBIt45Tm_BwZnTeYH8X4jwTgvpVD","timestamp":1714309139814}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}